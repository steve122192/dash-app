{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('simpleimputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('xgbregressor',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=1, gamma=0,\n",
       "                              importance_type='gain', learning_rate=0.1,\n",
       "                              max_delta_step=0, max_depth=10,\n",
       "                              min_child_weight=1, missing=None, n_estimators=10,\n",
       "                              n_jobs=-1, nthread=None, objective='reg:linear',\n",
       "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                              scale_pos_weight=1, seed=None, silent=None,\n",
       "                              subsample=1, verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "nfl=pd.read_csv('https://raw.githubusercontent.com/steve122192/Unit-2-Project/master/nfl.csv')\n",
    "\n",
    "# Clean NFL Data\n",
    "nfl = nfl[nfl['Rk'] != 'Rk']\n",
    "nfl['To'] = pd.to_numeric(nfl['To'])\n",
    "nfl['From'] = pd.to_numeric(nfl['From'])\n",
    "nfl['Games GS'] = pd.to_numeric(nfl['Games GS'])\n",
    "\n",
    "#Engineer Target ('starts_per_season')\n",
    "nfl['Seasons'] = (nfl['To']-nfl['From'])+1\n",
    "nfl = nfl[['Player','Seasons','Games GS']]\n",
    "nfl['starts_per_season'] = nfl['Games GS']/nfl['Seasons']\n",
    "nfl = nfl[['Player','starts_per_season']]\n",
    "\n",
    "\n",
    "college = pd.read_csv('https://raw.githubusercontent.com/steve122192/Unit-2-Project/master/college.csv')\n",
    "\n",
    "# Merge and Clean College Data\n",
    "df = pd.merge(nfl, college, on='Player', how='outer')\n",
    "df.dropna(subset=['Rk'], inplace=True)\n",
    "cols = df.columns[3:5]\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "cols = df.columns[6:]\n",
    "df[cols] = df[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "df = df[df['Player'] != 'Player']\n",
    "df['School'].fillna(value='multiple', inplace=True)\n",
    "\n",
    "# Engineer 'per_year' features\n",
    "df['pass_per_year'] = df['Passing Att']/(df['To']-df['From']+1)\n",
    "df = df[df['pass_per_year']>200]\n",
    "df['cmp_per_year'] = df['Passing Cmp']/(df['To']-df['From']+1)\n",
    "df['yds_per_year'] = df['Passing Yds']/(df['To']-df['From']+1)\n",
    "df['tds_per_year'] = df['Passing TD']/(df['To']-df['From']+1)\n",
    "df['int_per_year'] = df['Passing Int']/(df['To']-df['From']+1)\n",
    "\n",
    "#Clean before Merge\n",
    "df['starts_per_season'].fillna(value=0, inplace=True)\n",
    "df = df[df['To']<2017]\n",
    "df.drop(['Rk','From','To'], axis=1, inplace=True)\n",
    "\n",
    "# Clean & Merge Combine Data\n",
    "combine = pd.read_csv('https://raw.githubusercontent.com/steve122192/Unit-2-Project/master/combine.csv')\n",
    "combine.drop(['Year','POS','Wonderlic'], axis=1, inplace=True)\n",
    "combine.rename(columns = {'Name':'Player'}, inplace = True)\n",
    "df = pd.merge(df, combine, on='Player', how='left')\n",
    "df['no_combine'] = df['College'].isnull()\n",
    "\n",
    "# Engineer 'power_5' feature\n",
    "list1 = ['Boston College','Clemson','Duke','Florida State', 'Georgia Tech',\n",
    "         'Louisville','Miami (FL)','North Carolina','North Carolina State',\n",
    "         'Pittsburgh','Syracuse','Virginia','Virginia Tech','Wake Forest',\n",
    "         'Notre Dame','Illinois','Indiana','Iowa','Maryland','Michigan',\n",
    "         'Michigan State','Minnesota','Nebraska','Northwestern','Ohio State',\n",
    "         'Penn State','Purdue','Rutgers','Wisconsin','Baylor','Iowa State',\n",
    "         'Kansas','Kansas State','Oklahoma','Oklahoma State','Texas Christian',\n",
    "         'Texas','Texas Tech','West Virginia','Arizona','Arizona State',\n",
    "         'California','UCLA','Colorado','Oregon','Oregon State','Southern California',\n",
    "         'Stanford','Utah','Washington','Washington State','Alabama', 'Arkansas',\n",
    "         'Auburn','Florida','Georgia','Kentucky','Louisiana State','Mississippi',\n",
    "         'Mississippi State','South Carolina','Tennessee','Texas A&M','Vanderbilt',\n",
    "         'multiple']\n",
    "df['power_5'] = df['School'].apply(lambda school: school in list1)\n",
    "\n",
    "# Clean and Impute combine data\n",
    "df.drop(['College','Bench Press'], axis=1, inplace=True)\n",
    "forty_max = df['40 Yard'].max()\n",
    "vert_min = df['Vert Leap (in)'].min()\n",
    "broad_min = df['Broad Jump (in)'].min()\n",
    "shuttle_max = df['Shuttle'].max()\n",
    "cone_max = df['3Cone'].max()\n",
    "df['40 Yard'].fillna(value=forty_max, inplace=True)\n",
    "df['Vert Leap (in)'].fillna(value=vert_min, inplace=True)\n",
    "df['Broad Jump (in)'].fillna(value=broad_min, inplace=True)\n",
    "df['Shuttle'].fillna(value=shuttle_max, inplace=True)\n",
    "df['3Cone'].fillna(value=cone_max, inplace=True)\n",
    "df.drop(['School'], axis=1, inplace=True)\n",
    "\n",
    "# Clean & Merge conference championship data\n",
    "conference = pd.read_csv('https://raw.githubusercontent.com/steve122192/Unit-2-Project/master/conference_championships.csv')\n",
    "conference = conference[['Player','G']]\n",
    "conference = conference[conference['Player'] !='Player']\n",
    "conference['G'] = pd.to_numeric(conference['G'])\n",
    "conference.rename(columns = {'G':'Conference_Championships'}, inplace=True)\n",
    "df = pd.merge(df, conference, on='Player', how='left')\n",
    "df['Conference_Championships'].fillna(value=0, inplace=True)\n",
    "\n",
    "# Clean Win Data\n",
    "wins = pd.read_csv('https://raw.githubusercontent.com/steve122192/Unit-2-Project/master/wins.csv')\n",
    "wins = wins[wins['Player'] !='Player']\n",
    "wins['G'] = pd.to_numeric(wins['G'])\n",
    "wins['To'] = pd.to_numeric(wins['To'])\n",
    "wins['From'] = pd.to_numeric(wins['From'])\n",
    "\n",
    "# Engineer 'wins_per_season' feature\n",
    "wins['Seasons'] = (wins['To']-wins['From']+1)\n",
    "wins['wins_per_season'] = (wins['G']/wins['Seasons'])\n",
    "wins = wins[['Player','wins_per_season']]\n",
    "\n",
    "# Merge & Clean win data\n",
    "df = pd.merge(df, wins, on='Player', how='left')\n",
    "df['wins_per_season'].fillna(value=0, inplace=True)\n",
    "df.drop('Player', axis=1, inplace=True)\n",
    "\n",
    "# Rename Columns\n",
    "df.columns = ['starts_per_season','games_played','passing_completions','passing_attempts',\n",
    "              'passing_percentage','passing_yards','passing_tds','passing_ints',\n",
    "              'passer_rating','passes_per_year','completions_per_year','yards_per_year',\n",
    "              'tds_per_year','ints_per_year','height','weight','forty_yard_dash',\n",
    "              'vert_leap','broad_jump','shuttle_run','three_cone','no_combine_attendance',\n",
    "              'power_five_conf','conference_championships','wins_per_year']\n",
    "\n",
    "\n",
    "train, test =  train_test_split(df, train_size=.80, test_size=.2, random_state=42)\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "target = 'starts_per_season'\n",
    "X_train = train.drop(target, axis=1)\n",
    "y_train = train[target]\n",
    "X_test = test.drop(target, axis=1)\n",
    "y_test = test[target]\n",
    "\n",
    "\n",
    "# Use best parameters\n",
    "pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler(),\n",
    "    XGBRegressor(n_estimators=10, learning_rate=0.1, max_depth=10, n_jobs=-1)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  1.4292250435490166\n",
      "Test R2:  0.21357401958355315\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Test MAE: ',mae)\n",
    "print('Test R2: ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib==0.14.1\n",
      "scikit-learn==0.22.1\n",
      "xgboost==0.90\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import sklearn\n",
    "import xgboost\n",
    "print(f'joblib=={joblib.__version__}')\n",
    "print(f'scikit-learn=={sklearn.__version__}')\n",
    "print(f'xgboost=={xgboost.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(pipeline, 'pipeline.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['starts_per_season',\n",
       " 'games_played',\n",
       " 'passing_completions',\n",
       " 'passing_attempts',\n",
       " 'passing_percentage',\n",
       " 'passing_yards',\n",
       " 'passing_tds',\n",
       " 'passing_ints',\n",
       " 'passer_rating',\n",
       " 'passes_per_year',\n",
       " 'completions_per_year',\n",
       " 'yards_per_year',\n",
       " 'tds_per_year',\n",
       " 'ints_per_year',\n",
       " 'height',\n",
       " 'weight',\n",
       " 'forty_yard_dash',\n",
       " 'vert_leap',\n",
       " 'broad_jump',\n",
       " 'shuttle_run',\n",
       " 'three_cone',\n",
       " 'no_combine_attendance',\n",
       " 'power_five_conf',\n",
       " 'conference_championships',\n",
       " 'wins_per_year']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
